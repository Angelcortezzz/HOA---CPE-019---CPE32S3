{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Technological Institute of the Philippines | Quezon City - Computer Engineering\n",
        "--- | ---\n",
        "Course Code: | CPE 019\n",
        "Code Title: | Emerging Technologies in CpE 2 - Saving Models\n",
        "<hr> | <hr>\n",
        "<u>**CPE019 Assignment (2nd Sem, A.Y. 2023-2024)** | **Assignment 8.1**\n",
        "**Name** | Cortez, Angelica\n",
        "**Section** | CPE32S3\n",
        "**Schedule**: |Wednesday - 10:30am - 1:30pm\n",
        "**Date Performed**: |04/15/2024\n",
        "**Date Submitted**: |04/19/2024\n",
        "**Instructor**: | Engr.Roman Richard\n",
        "<hr>"
      ],
      "metadata": {
        "id": "XvDeEl8mrGor"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instructions:\n",
        "\n",
        "1. Choose any dataset applicable to either a classification problem or a regression problem.\n",
        "\n",
        "\n",
        "\n",
        "2. Explain your datasets and the problem being addressed.\n",
        "\n",
        "\n",
        "\n",
        "3. Show evidence that you can do the following:\n",
        "\n",
        "\n",
        "\n",
        "* Save a model in HDF5 format\n",
        "* Save a model and load the model in a JSON format\n",
        "* Save a model and load the model in a YAML format\n",
        "* Checkpoint Neural Network Model Improvements\n",
        "* Checkpoint Best Neural Network Model only\n",
        "* Load a saved Neural Network model\n",
        "* Visualize Model Training History in Keras\n",
        "* Show the application of Dropout Regularization\n",
        "* Show the application of Dropout on the visible layer\n",
        "* Show the application of Dropout on the hidden layer\n",
        "* Show the application of a time-based learning rate schedule\n",
        "* Show the application of a drop-based learning rate schedule"
      ],
      "metadata": {
        "id": "LCm0nj8drJ_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ABOUT THE DATASET\n",
        "### Maternal Health Risk Dataset\n",
        "\n",
        "The dataset comprises demographic and health-related data collected via IoT devices from various healthcare facilities in rural Bangladesh, focusing on risk factors for maternal mortality. Variables include age, systolic and diastolic blood pressure, blood sugar levels, body temperature, heart rate, and risk level, with risk level being the target variable. The problem addressed is classification, aiming to predict the intensity level of maternal mortality risk based on the mentioned attributes."
      ],
      "metadata": {
        "id": "T4075k7zrLwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FEATURES:\n",
        "\n",
        "* Age - Any age in years when a woman is pregnant\n",
        "\n",
        "\n",
        "* SystolicBP - Upper value of Blood Pressure\n",
        "\n",
        "\n",
        "* DiastolicBP - Lower value of Blood Pressure\n",
        "\n",
        "\n",
        "* BS - Blood glucose levels in terms of molar concentration\n",
        "\n",
        "* BodyTemp - Body temperature\n",
        "\n",
        "* HeartRate - Resting heart rate\n",
        "\n",
        "TARGET VARIABLE:\n",
        "\n",
        "* Donated_Blood - Target\tBinary whether the individual donated blood in March 2007 (1 stand for donating blood; 0 stands for not donating blood)\n",
        "\n",
        "\n",
        "\n",
        "SOURCE OF THE DATASET: https://archive.ics.uci.edu/dataset/863/maternal+health+risk?fbclid=IwZXh0bgNhZW0CMTAAAR2uVRrYT2dbfvWrt-zACYPxu8cQ0H7jXuyn3BpJJL6pcsDjia2VdwNrs7c_aem_ASWgLOrj6-96z-7OEw6AoSVf-7SXdYZhj9Z58-QjzGOtA8Yo18jdHU7_CHgMLu2aDnJr2zMEFyb6JUV-iBgQNNeR"
      ],
      "metadata": {
        "id": "6Kv_CtcLrRkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREPROCESSING OF DATA"
      ],
      "metadata": {
        "id": "i_V8ZYlFrHpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras"
      ],
      "metadata": {
        "id": "vCB7kuH5rW-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4678012-1c6a-4f4c-94fe-9f95d40775f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting keras>=3.2.0 (from scikeras)\n",
            "  Downloading keras-3.2.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn>=1.4.2 (from scikeras)\n",
            "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.7.1)\n",
            "Collecting namex (from keras>=3.2.0->scikeras)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.9.0)\n",
            "Collecting optree (from keras>=3.2.0->scikeras)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.11.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
            "Installing collected packages: namex, optree, scikit-learn, keras, scikeras\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.2.1 namex-0.0.8 optree-0.11.0 scikeras-0.13.0 scikit-learn-1.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install np_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88hMe639rlI1",
        "outputId": "2ba20192-7a66-41e7-9ab3-5c4ea46a6e83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting np_utils\n",
            "  Downloading np_utils-0.6.0.tar.gz (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from np_utils) (1.25.2)\n",
            "Building wheels for collected packages: np_utils\n",
            "  Building wheel for np_utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for np_utils: filename=np_utils-0.6.0-py3-none-any.whl size=56441 sha256=d26540c15165845836213dabe3e5b6a9dcb76a0a36ae79db978d7e090625d114\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/c7/50/2307607f44366dd021209f660045f8d51cb976514d30be7cc7\n",
            "Successfully built np_utils\n",
            "Installing collected packages: np_utils\n",
            "Successfully installed np_utils-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ye9av2XmrsDd",
        "outputId": "9a3ebee1-6fe4-4e2d-b9bc-12d63e38a578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.15.0\n",
            "Uninstalling tensorflow-2.15.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow-2.15.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled tensorflow-2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow==2.12.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1627
        },
        "id": "PzQyrcrMrvDO",
        "outputId": "c1816ccc-eed7-4f52-c539-09eb325b55ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.12.0\n",
            "  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m731.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.3.25)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.62.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.4.26)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow==2.12.0)\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.16.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12.0)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12.0)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12.0) (0.36.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.43.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.11.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, numpy, keras, gast, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.2.1\n",
            "    Uninstalling keras-3.2.1:\n",
            "      Successfully uninstalled keras-3.2.1\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.4\n",
            "    Uninstalling gast-0.5.4:\n",
            "      Successfully uninstalled gast-0.5.4\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.0\n",
            "    Uninstalling google-auth-oauthlib-1.2.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
            "scikeras 0.13.0 requires keras>=3.2.0, but you have keras 2.12.0 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 keras-2.12.0 numpy-1.23.5 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "de65457f7d9d41189fcb71e681cc26e4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "\n",
        "import numpy\n",
        "import pandas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "T4GPwtJarmeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "MHealthRisk_df = pd.read_csv(\"/content/Maternal Health Risk Data Set.csv\")\n",
        "\n",
        "dataset = MHealthRisk_df"
      ],
      "metadata": {
        "id": "Gw6bImoAro1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MHealthRisk_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ZPxIU3wrsI1I",
        "outputId": "31bd147b-db2c-435b-a06d-91ad8e67f9a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Age  SystolicBP  DiastolicBP    BS  BodyTemp  HeartRate  RiskLevel\n",
              "0      25         130           80  15.0      98.0         86  high risk\n",
              "1      35         140           90  13.0      98.0         70  high risk\n",
              "2      29          90           70   8.0     100.0         80  high risk\n",
              "3      30         140           85   7.0      98.0         70  high risk\n",
              "4      35         120           60   6.1      98.0         76   low risk\n",
              "...   ...         ...          ...   ...       ...        ...        ...\n",
              "1009   22         120           60  15.0      98.0         80  high risk\n",
              "1010   55         120           90  18.0      98.0         60  high risk\n",
              "1011   35          85           60  19.0      98.0         86  high risk\n",
              "1012   43         120           90  18.0      98.0         70  high risk\n",
              "1013   32         120           65   6.0     101.0         76   mid risk\n",
              "\n",
              "[1014 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3b6cd22e-4850-47fc-b29e-13be5a0e6b3e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>SystolicBP</th>\n",
              "      <th>DiastolicBP</th>\n",
              "      <th>BS</th>\n",
              "      <th>BodyTemp</th>\n",
              "      <th>HeartRate</th>\n",
              "      <th>RiskLevel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>130</td>\n",
              "      <td>80</td>\n",
              "      <td>15.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>86</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>140</td>\n",
              "      <td>90</td>\n",
              "      <td>13.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>70</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29</td>\n",
              "      <td>90</td>\n",
              "      <td>70</td>\n",
              "      <td>8.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>80</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "      <td>140</td>\n",
              "      <td>85</td>\n",
              "      <td>7.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>70</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35</td>\n",
              "      <td>120</td>\n",
              "      <td>60</td>\n",
              "      <td>6.1</td>\n",
              "      <td>98.0</td>\n",
              "      <td>76</td>\n",
              "      <td>low risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1009</th>\n",
              "      <td>22</td>\n",
              "      <td>120</td>\n",
              "      <td>60</td>\n",
              "      <td>15.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>80</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1010</th>\n",
              "      <td>55</td>\n",
              "      <td>120</td>\n",
              "      <td>90</td>\n",
              "      <td>18.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>60</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1011</th>\n",
              "      <td>35</td>\n",
              "      <td>85</td>\n",
              "      <td>60</td>\n",
              "      <td>19.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>86</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1012</th>\n",
              "      <td>43</td>\n",
              "      <td>120</td>\n",
              "      <td>90</td>\n",
              "      <td>18.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>70</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1013</th>\n",
              "      <td>32</td>\n",
              "      <td>120</td>\n",
              "      <td>65</td>\n",
              "      <td>6.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>76</td>\n",
              "      <td>mid risk</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1014 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b6cd22e-4850-47fc-b29e-13be5a0e6b3e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3b6cd22e-4850-47fc-b29e-13be5a0e6b3e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3b6cd22e-4850-47fc-b29e-13be5a0e6b3e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-545d801d-089c-4d07-a221-29e768809add\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-545d801d-089c-4d07-a221-29e768809add')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-545d801d-089c-4d07-a221-29e768809add button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "MHealthRisk_df",
              "summary": "{\n  \"name\": \"MHealthRisk_df\",\n  \"rows\": 1014,\n  \"fields\": [\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 10,\n        \"max\": 70,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          40,\n          43,\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SystolicBP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18,\n        \"min\": 70,\n        \"max\": 160,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          130,\n          110,\n          80\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DiastolicBP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 49,\n        \"max\": 100,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          80,\n          90,\n          89\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.293531721151281,\n        \"min\": 6.0,\n        \"max\": 19.0,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          6.5,\n          7.7,\n          7.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BodyTemp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3713843755995376,\n        \"min\": 98.0,\n        \"max\": 103.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          100.0,\n          98.4,\n          98.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HeartRate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 7,\n        \"max\": 90,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          86,\n          70,\n          77\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RiskLevel\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"high risk\",\n          \"low risk\",\n          \"mid risk\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MHealthRisk_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lmd4UDDxsKAE",
        "outputId": "2429eb8b-91ff-44a9-bcd2-dc37d7b442b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1014 entries, 0 to 1013\n",
            "Data columns (total 7 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   Age          1014 non-null   int64  \n",
            " 1   SystolicBP   1014 non-null   int64  \n",
            " 2   DiastolicBP  1014 non-null   int64  \n",
            " 3   BS           1014 non-null   float64\n",
            " 4   BodyTemp     1014 non-null   float64\n",
            " 5   HeartRate    1014 non-null   int64  \n",
            " 6   RiskLevel    1014 non-null   object \n",
            "dtypes: float64(2), int64(4), object(1)\n",
            "memory usage: 55.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MHealthRisk_df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlC1LmIIsK9m",
        "outputId": "bcf8dcc5-1e2c-477d-e75f-e932c05c91cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age            0\n",
              "SystolicBP     0\n",
              "DiastolicBP    0\n",
              "BS             0\n",
              "BodyTemp       0\n",
              "HeartRate      0\n",
              "RiskLevel      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scale_LE = LabelEncoder()\n",
        "for i in MHealthRisk_df:\n",
        "  if MHealthRisk_df[i].dtypes == 'object':\n",
        "    MHealthRisk_df[i] = scale_LE.fit_transform(MHealthRisk_df[i])\n",
        "  else:\n",
        "    pass\n",
        "MHealthRisk_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S27hlpEWsL7o",
        "outputId": "38f96ea7-43de-4041-e09d-ad552c7e511d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1014 entries, 0 to 1013\n",
            "Data columns (total 7 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   Age          1014 non-null   int64  \n",
            " 1   SystolicBP   1014 non-null   int64  \n",
            " 2   DiastolicBP  1014 non-null   int64  \n",
            " 3   BS           1014 non-null   float64\n",
            " 4   BodyTemp     1014 non-null   float64\n",
            " 5   HeartRate    1014 non-null   int64  \n",
            " 6   RiskLevel    1014 non-null   int64  \n",
            "dtypes: float64(2), int64(5)\n",
            "memory usage: 55.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MHealthRisk_df.sample(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "c2JOA8PmsM6k",
        "outputId": "ec1812c6-d6ce-445f-c6a4-2afed770dc84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Age  SystolicBP  DiastolicBP    BS  BodyTemp  HeartRate  RiskLevel\n",
              "419    17         140          100   6.8     103.0         80          0\n",
              "925    42          90           60   7.5      98.0         76          1\n",
              "957    14          90           65   7.0     101.0         70          0\n",
              "1004   13          90           65   9.0     101.0         80          0\n",
              "608    35         100           70   7.5      98.0         66          1\n",
              "618    23         120           90   7.5      98.0         70          1\n",
              "955    40         140          100  18.0      98.0         90          0\n",
              "130    40         160          100  19.0      98.0         77          0\n",
              "72     19         120           80   7.0      98.0         70          2\n",
              "287    17          90           65   7.7     103.0         67          0\n",
              "261    19         120           75   6.9      98.0         66          1\n",
              "468    25         140          100   6.8      98.0         80          0\n",
              "285    13          90           65   9.0     101.0         80          0\n",
              "932    49         120           90   7.5      98.0         77          1\n",
              "893    15          76           49   7.9      98.0         77          1\n",
              "839    28          85           60   9.0     101.0         86          2\n",
              "518    19          90           70   7.5      98.0         80          1\n",
              "91     60         120           85  15.0      98.0         60          2\n",
              "570    29         130           70   7.5      98.0         78          2\n",
              "520    31         120           60   6.1      98.0         76          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-988d9497-0093-404b-bc49-3a38246d4e7f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>SystolicBP</th>\n",
              "      <th>DiastolicBP</th>\n",
              "      <th>BS</th>\n",
              "      <th>BodyTemp</th>\n",
              "      <th>HeartRate</th>\n",
              "      <th>RiskLevel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>419</th>\n",
              "      <td>17</td>\n",
              "      <td>140</td>\n",
              "      <td>100</td>\n",
              "      <td>6.8</td>\n",
              "      <td>103.0</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>925</th>\n",
              "      <td>42</td>\n",
              "      <td>90</td>\n",
              "      <td>60</td>\n",
              "      <td>7.5</td>\n",
              "      <td>98.0</td>\n",
              "      <td>76</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>957</th>\n",
              "      <td>14</td>\n",
              "      <td>90</td>\n",
              "      <td>65</td>\n",
              "      <td>7.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1004</th>\n",
              "      <td>13</td>\n",
              "      <td>90</td>\n",
              "      <td>65</td>\n",
              "      <td>9.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>608</th>\n",
              "      <td>35</td>\n",
              "      <td>100</td>\n",
              "      <td>70</td>\n",
              "      <td>7.5</td>\n",
              "      <td>98.0</td>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>618</th>\n",
              "      <td>23</td>\n",
              "      <td>120</td>\n",
              "      <td>90</td>\n",
              "      <td>7.5</td>\n",
              "      <td>98.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>955</th>\n",
              "      <td>40</td>\n",
              "      <td>140</td>\n",
              "      <td>100</td>\n",
              "      <td>18.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>90</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>40</td>\n",
              "      <td>160</td>\n",
              "      <td>100</td>\n",
              "      <td>19.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>19</td>\n",
              "      <td>120</td>\n",
              "      <td>80</td>\n",
              "      <td>7.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>70</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>17</td>\n",
              "      <td>90</td>\n",
              "      <td>65</td>\n",
              "      <td>7.7</td>\n",
              "      <td>103.0</td>\n",
              "      <td>67</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>19</td>\n",
              "      <td>120</td>\n",
              "      <td>75</td>\n",
              "      <td>6.9</td>\n",
              "      <td>98.0</td>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>468</th>\n",
              "      <td>25</td>\n",
              "      <td>140</td>\n",
              "      <td>100</td>\n",
              "      <td>6.8</td>\n",
              "      <td>98.0</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>13</td>\n",
              "      <td>90</td>\n",
              "      <td>65</td>\n",
              "      <td>9.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>932</th>\n",
              "      <td>49</td>\n",
              "      <td>120</td>\n",
              "      <td>90</td>\n",
              "      <td>7.5</td>\n",
              "      <td>98.0</td>\n",
              "      <td>77</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>893</th>\n",
              "      <td>15</td>\n",
              "      <td>76</td>\n",
              "      <td>49</td>\n",
              "      <td>7.9</td>\n",
              "      <td>98.0</td>\n",
              "      <td>77</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839</th>\n",
              "      <td>28</td>\n",
              "      <td>85</td>\n",
              "      <td>60</td>\n",
              "      <td>9.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>86</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>19</td>\n",
              "      <td>90</td>\n",
              "      <td>70</td>\n",
              "      <td>7.5</td>\n",
              "      <td>98.0</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>60</td>\n",
              "      <td>120</td>\n",
              "      <td>85</td>\n",
              "      <td>15.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>60</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570</th>\n",
              "      <td>29</td>\n",
              "      <td>130</td>\n",
              "      <td>70</td>\n",
              "      <td>7.5</td>\n",
              "      <td>98.0</td>\n",
              "      <td>78</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>31</td>\n",
              "      <td>120</td>\n",
              "      <td>60</td>\n",
              "      <td>6.1</td>\n",
              "      <td>98.0</td>\n",
              "      <td>76</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-988d9497-0093-404b-bc49-3a38246d4e7f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-988d9497-0093-404b-bc49-3a38246d4e7f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-988d9497-0093-404b-bc49-3a38246d4e7f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-771b3801-aabd-4325-8000-ede3abce5043\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-771b3801-aabd-4325-8000-ede3abce5043')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-771b3801-aabd-4325-8000-ede3abce5043 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"MHealthRisk_df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 13,\n        \"max\": 60,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          49,\n          28,\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SystolicBP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23,\n        \"min\": 76,\n        \"max\": 160,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          90,\n          76,\n          140\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DiastolicBP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16,\n        \"min\": 49,\n        \"max\": 100,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          49,\n          60,\n          80\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.726844297935269,\n        \"min\": 6.1,\n        \"max\": 19.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          19.0,\n          6.8,\n          15.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BodyTemp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8035053587243282,\n        \"min\": 98.0,\n        \"max\": 103.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          103.0,\n          98.0,\n          101.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HeartRate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 60,\n        \"max\": 90,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          60,\n          76,\n          77\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RiskLevel\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***ANALYSIS:***\n",
        "The provided code begins by installing necessary packages like scikeras and np_utils. It then imports essential libraries such as numpy, pandas, seaborn, and matplotlib for data manipulation and visualization. The dataset \"Maternal Health Risk Data Set\" is loaded into a DataFrame named MHealthRisk_df. Information about the dataset, including data types and missing values, is displayed. Following this, label encoding is applied to transform categorical variables into numerical values if their data type is 'object'. Finally, a sample of 20 rows from the modified DataFrame is displayed for inspection. Overall, the code performs data preparation tasks, including data loading, preprocessing, and initial exploration, which are fundamental steps in any machine learning project."
      ],
      "metadata": {
        "id": "vJcz2MeY62u6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MHealthRisk_df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "hRdDfFFdsN-Y",
        "outputId": "e97c750d-f435-46b2-eb6b-9b8afe521220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Age   SystolicBP  DiastolicBP           BS     BodyTemp  \\\n",
              "count  1014.000000  1014.000000  1014.000000  1014.000000  1014.000000   \n",
              "mean     29.871795   113.198225    76.460552     8.725986    98.665089   \n",
              "std      13.474386    18.403913    13.885796     3.293532     1.371384   \n",
              "min      10.000000    70.000000    49.000000     6.000000    98.000000   \n",
              "25%      19.000000   100.000000    65.000000     6.900000    98.000000   \n",
              "50%      26.000000   120.000000    80.000000     7.500000    98.000000   \n",
              "75%      39.000000   120.000000    90.000000     8.000000    98.000000   \n",
              "max      70.000000   160.000000   100.000000    19.000000   103.000000   \n",
              "\n",
              "         HeartRate    RiskLevel  \n",
              "count  1014.000000  1014.000000  \n",
              "mean     74.301775     1.063116  \n",
              "std       8.088702     0.772146  \n",
              "min       7.000000     0.000000  \n",
              "25%      70.000000     0.000000  \n",
              "50%      76.000000     1.000000  \n",
              "75%      80.000000     2.000000  \n",
              "max      90.000000     2.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac74af19-52eb-401a-80a2-ada71dbf315a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>SystolicBP</th>\n",
              "      <th>DiastolicBP</th>\n",
              "      <th>BS</th>\n",
              "      <th>BodyTemp</th>\n",
              "      <th>HeartRate</th>\n",
              "      <th>RiskLevel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1014.000000</td>\n",
              "      <td>1014.000000</td>\n",
              "      <td>1014.000000</td>\n",
              "      <td>1014.000000</td>\n",
              "      <td>1014.000000</td>\n",
              "      <td>1014.000000</td>\n",
              "      <td>1014.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>29.871795</td>\n",
              "      <td>113.198225</td>\n",
              "      <td>76.460552</td>\n",
              "      <td>8.725986</td>\n",
              "      <td>98.665089</td>\n",
              "      <td>74.301775</td>\n",
              "      <td>1.063116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>13.474386</td>\n",
              "      <td>18.403913</td>\n",
              "      <td>13.885796</td>\n",
              "      <td>3.293532</td>\n",
              "      <td>1.371384</td>\n",
              "      <td>8.088702</td>\n",
              "      <td>0.772146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>19.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>26.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>39.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>70.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac74af19-52eb-401a-80a2-ada71dbf315a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ac74af19-52eb-401a-80a2-ada71dbf315a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ac74af19-52eb-401a-80a2-ada71dbf315a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ddaf672c-d607-4908-9ee6-92e8218fc029\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ddaf672c-d607-4908-9ee6-92e8218fc029')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ddaf672c-d607-4908-9ee6-92e8218fc029 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"MHealthRisk_df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 348.54126044861886,\n        \"min\": 10.0,\n        \"max\": 1014.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          29.871794871794872,\n          26.0,\n          1014.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SystolicBP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 325.7381080591285,\n        \"min\": 18.403912756342706,\n        \"max\": 1014.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1014.0,\n          113.19822485207101,\n          120.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DiastolicBP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 335.61546340338174,\n        \"min\": 13.885795724160687,\n        \"max\": 1014.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          76.46055226824457,\n          80.0,\n          1014.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 355.5316275877343,\n        \"min\": 3.293531721151281,\n        \"max\": 1014.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          8.725986193293886,\n          7.5,\n          1014.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BodyTemp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 330.2234922746751,\n        \"min\": 1.3713843755995376,\n        \"max\": 1014.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          98.66508875739645,\n          103.0,\n          1.3713843755995376\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HeartRate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 339.57400097574833,\n        \"min\": 7.0,\n        \"max\": 1014.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          74.30177514792899,\n          76.0,\n          1014.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RiskLevel\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 358.15871327250414,\n        \"min\": 0.0,\n        \"max\": 1014.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1014.0,\n          1.0631163708086786,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MHealthRisk_df.corr()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "X8gSTPcYsOzg",
        "outputId": "79ee0c73-8dc1-43c7-ded9-0d5ddd929835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Age  SystolicBP  DiastolicBP        BS  BodyTemp  HeartRate  \\\n",
              "Age          1.000000    0.416045     0.398026  0.473284 -0.255323   0.079798   \n",
              "SystolicBP   0.416045    1.000000     0.787006  0.425172 -0.286616  -0.023108   \n",
              "DiastolicBP  0.398026    0.787006     1.000000  0.423824 -0.257538  -0.046151   \n",
              "BS           0.473284    0.425172     0.423824  1.000000 -0.103493   0.142867   \n",
              "BodyTemp    -0.255323   -0.286616    -0.257538 -0.103493  1.000000   0.098771   \n",
              "HeartRate    0.079798   -0.023108    -0.046151  0.142867  0.098771   1.000000   \n",
              "RiskLevel   -0.211851   -0.208797    -0.284633 -0.479958 -0.006680  -0.111637   \n",
              "\n",
              "             RiskLevel  \n",
              "Age          -0.211851  \n",
              "SystolicBP   -0.208797  \n",
              "DiastolicBP  -0.284633  \n",
              "BS           -0.479958  \n",
              "BodyTemp     -0.006680  \n",
              "HeartRate    -0.111637  \n",
              "RiskLevel     1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7804110e-3660-485a-bad5-a50f61665db0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>SystolicBP</th>\n",
              "      <th>DiastolicBP</th>\n",
              "      <th>BS</th>\n",
              "      <th>BodyTemp</th>\n",
              "      <th>HeartRate</th>\n",
              "      <th>RiskLevel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.416045</td>\n",
              "      <td>0.398026</td>\n",
              "      <td>0.473284</td>\n",
              "      <td>-0.255323</td>\n",
              "      <td>0.079798</td>\n",
              "      <td>-0.211851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SystolicBP</th>\n",
              "      <td>0.416045</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.787006</td>\n",
              "      <td>0.425172</td>\n",
              "      <td>-0.286616</td>\n",
              "      <td>-0.023108</td>\n",
              "      <td>-0.208797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DiastolicBP</th>\n",
              "      <td>0.398026</td>\n",
              "      <td>0.787006</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.423824</td>\n",
              "      <td>-0.257538</td>\n",
              "      <td>-0.046151</td>\n",
              "      <td>-0.284633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BS</th>\n",
              "      <td>0.473284</td>\n",
              "      <td>0.425172</td>\n",
              "      <td>0.423824</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.103493</td>\n",
              "      <td>0.142867</td>\n",
              "      <td>-0.479958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BodyTemp</th>\n",
              "      <td>-0.255323</td>\n",
              "      <td>-0.286616</td>\n",
              "      <td>-0.257538</td>\n",
              "      <td>-0.103493</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.098771</td>\n",
              "      <td>-0.006680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HeartRate</th>\n",
              "      <td>0.079798</td>\n",
              "      <td>-0.023108</td>\n",
              "      <td>-0.046151</td>\n",
              "      <td>0.142867</td>\n",
              "      <td>0.098771</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.111637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RiskLevel</th>\n",
              "      <td>-0.211851</td>\n",
              "      <td>-0.208797</td>\n",
              "      <td>-0.284633</td>\n",
              "      <td>-0.479958</td>\n",
              "      <td>-0.006680</td>\n",
              "      <td>-0.111637</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7804110e-3660-485a-bad5-a50f61665db0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7804110e-3660-485a-bad5-a50f61665db0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7804110e-3660-485a-bad5-a50f61665db0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-61973282-87a5-46da-955a-190959a021c8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-61973282-87a5-46da-955a-190959a021c8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-61973282-87a5-46da-955a-190959a021c8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"MHealthRisk_df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4389859865570124,\n        \"min\": -0.25532313920501565,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1.0,\n          0.4160454479747322,\n          0.0797976348285774\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SystolicBP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4939108178226137,\n        \"min\": -0.2866155235428736,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.4160454479747322,\n          1.0,\n          -0.023107956988353304\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DiastolicBP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.50393125749222,\n        \"min\": -0.2846334952168584,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.3980262867031837,\n          0.78700647697753,\n          -0.04615057091697736\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4725907093021242,\n        \"min\": -0.4799580508546492,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.4732843359291685,\n          0.4251716592710181,\n          0.14286722659941492\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BodyTemp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4525973307113755,\n        \"min\": -0.2866155235428736,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          -0.25532313920501565,\n          -0.2866155235428736,\n          0.09877104396427468\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HeartRate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.37987456818871423,\n        \"min\": -0.11163740035420522,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.0797976348285774,\n          -0.023107956988353304,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RiskLevel\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4829073009411157,\n        \"min\": -0.4799580508546492,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          -0.21185116042052668,\n          -0.2087971130640691,\n          -0.11163740035420522\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Analysis\n",
        "\n",
        "# using heatmap\n",
        "plt.figure(figsize=(12,10))\n",
        "sns.heatmap(MHealthRisk_df.corr(), annot=True, cmap = \"coolwarm\")\n",
        "plt.title(\"Correlation Heatmap of Variables\", fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "id": "ujnS0wQusP3A",
        "outputId": "c0719699-2eb4-400d-a025-2ef083108ceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***ANALYSIS:***\n",
        "\n",
        "The code begins by generating descriptive statistics for the DataFrame MHealthRisk_df, providing an overview of the numerical variables. It then calculates the correlation matrix for all variables in the dataset. Subsequently, a heatmap visualization of the correlation matrix is generated using seaborn, depicting the strength and direction of relationships between variables. SystolicBP and DiastolicBP exhibit a notably high positive correlation (correlation coefficient = 0.79), indicating multicollinearity, which could potentially impact the accuracy of predictive models due to redundant information between these variables."
      ],
      "metadata": {
        "id": "4pDJ3ggXsQsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop the SystolicBP\n",
        "drop_mutilcol = MHealthRisk_df.drop([\"SystolicBP\"], axis=1)"
      ],
      "metadata": {
        "id": "1x21XapBsS27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK OUTLIERS\n",
        "corr_var = MHealthRisk_df.corr()\n",
        "corr_targ = corr_var['Age']\n",
        "corr_abs = corr_targ.abs()\n",
        "low_corr = corr_abs[corr_abs <= 0.1].index.tolist()\n",
        "print(low_corr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBg05dDvsUTS",
        "outputId": "c620ba2e-e7af-422a-8d99-c39dff8ca514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['HeartRate']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# REMOVE OUTLIER\n",
        "\n",
        "rem_out = MHealthRisk_df.drop(columns = low_corr)\n",
        "MHealthRisk_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hj7TNeLxsVfE",
        "outputId": "818c2d65-2765-4042-e651-09674c106d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1014 entries, 0 to 1013\n",
            "Data columns (total 7 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   Age          1014 non-null   int64  \n",
            " 1   SystolicBP   1014 non-null   int64  \n",
            " 2   DiastolicBP  1014 non-null   int64  \n",
            " 3   BS           1014 non-null   float64\n",
            " 4   BodyTemp     1014 non-null   float64\n",
            " 5   HeartRate    1014 non-null   int64  \n",
            " 6   RiskLevel    1014 non-null   int64  \n",
            "dtypes: float64(2), int64(5)\n",
            "memory usage: 55.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***ANALYSIS:***\n",
        "\n",
        "The code analyzes the correlation of variables in the MHealthRisk_df DataFrame with the target variable 'Age'. It identifies variables with a correlation coefficient below or equal to 0.1, indicating low correlation with 'Age'. In this case, only 'HeartRate' falls within this threshold. Consequently, 'HeartRate' is deemed as an outlier and is removed from the DataFrame using the drop() function. Finally, the code displays the updated information about the DataFrame, reflecting the removal of the outlier variable 'HeartRate'."
      ],
      "metadata": {
        "id": "qe-AGZvosXHU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SPLITTING DATA"
      ],
      "metadata": {
        "id": "n6BIlWd2sZkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# split the data to separate features (X) and target labels (Y)\n",
        "x = MHealthRisk_df.drop(columns = 'RiskLevel')\n",
        "y = MHealthRisk_df['RiskLevel']\n",
        "\n",
        "# standardized the features using standardscaler\n",
        "standard_scale = StandardScaler()\n",
        "x_norm = standard_scale.fit_transform(x)\n",
        "\n",
        "# split the dataset into training and testing sets (70% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_norm, y, test_size = 0.2, random_state = 1111)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPnEQbmysbED",
        "outputId": "5eeb5436-9153-43ad-887c-041e3ec21064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((811, 6), (203, 6), (811,), (203,))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pie(MHealthRisk_df.RiskLevel.value_counts(),\n",
        "\t\tlabels= ['high risk', 'low risk', 'mid risk'],\n",
        "\t\tautopct='%.f', shadow=True)\n",
        "plt.title('Outcome Proportionality')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "Zyb4ect2sbXD",
        "outputId": "644669cd-20ad-4d8e-d6d6-b0da53f0231c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BUILD MODEL"
      ],
      "metadata": {
        "id": "-a3mC0AlshYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "utils_le = LabelEncoder()\n",
        "utils_le.fit(y_train)\n",
        "y_utils_le = utils_le.transform(y_train)\n",
        "encoded_y = to_categorical(y_utils_le)"
      ],
      "metadata": {
        "id": "_r2r4ByfsbQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DEFINE THE NEURAL NETWORK\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(6,)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "DDQZXdZpskyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING THE MODEL\n",
        "# Fit the model\n",
        "model.fit(X_train, encoded_y, epochs=3000, batch_size=64, verbose=0)\n",
        "\n",
        "# EVALUATE\n",
        "scores = model.evaluate(X_train, encoded_y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEQ1nRqAspya",
        "outputId": "e1d41055-3780-49f7-be7b-24c5da47a55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 83.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***ANALYSIS:***\n",
        "\n",
        "The code begins by encoding the target variable 'y_train' using LabelEncoder and then converting it into categorical format using to_categorical from TensorFlow.keras.utils. Subsequently, a neural network model is defined using the Sequential API with various dense layers. The model is compiled with categorical_crossentropy as the loss function, SGD optimizer, and accuracy as the evaluation metric. Following this, the model is trained on the training data 'X_train' and the encoded target variable 'encoded_y' for 3000 epochs with a batch size of 64. Finally, the model's accuracy on the training data is evaluated and printed, yielding an accuracy of 83.60%."
      ],
      "metadata": {
        "id": "lvkc7MJe8vgN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save a model in HDF5 format"
      ],
      "metadata": {
        "id": "GjJJNZgQsq2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTgzK2TvssUx",
        "outputId": "4be75a63-2274-40a6-8a7a-73279d41f257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install h5py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlioiYlGssld",
        "outputId": "1aff6914-8e62-43f2-df4e-102f695dec2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***ANALYSIS:***\n",
        "\n",
        "The code imports the to_categorical function from TensorFlow.keras.utils for one-hot encoding categorical variables and then mounts Google Drive onto the Colab environment using the drive.mount() function to access files stored on Google Drive. Additionally, it installs the h5py package, which is commonly used for saving and loading models in the Hierarchical Data Format (HDF5) format. These steps indicate the setup required for utilizing specific functionalities and accessing external data sources within the Colab environment for tasks such as machine learning model development and data analysis."
      ],
      "metadata": {
        "id": "_dPijVox_SI1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save a model and load the model in a JSON format"
      ],
      "metadata": {
        "id": "nSRJ-AQesucn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.models import  model_from_json\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "metadata": {
        "id": "5ihRWdiHswgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load json model\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)"
      ],
      "metadata": {
        "id": "qh8rjDZeswLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save a model\n",
        "model.save_weights(\"/content/drive/MyDrive/Colab Notebooks/model.weights.h5\")\n",
        "print(\"Saved model to disk as a JSON format\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG-4U816s0iR",
        "outputId": "c2e63b2c-a760-4706-9fcc-ca93643a4c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk as a JSON format\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load weights into new model\n",
        "loaded_model.load_weights(\"/content/drive/MyDrive/Colab Notebooks/model.weights.h5\")\n",
        "print(\"Loaded model from disk as a JSON format\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qz95utZs2Qx",
        "outputId": "17376c53-d3e5-4b1b-e813-04397a4dee59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from disk as a JSON format\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate loaded model\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X_train, encoded_y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4Chv1SRs3PZ",
        "outputId": "8fa883a0-723e-4550-81c8-150fc7958cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 83.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***ANALYSIS:***\n",
        "\n",
        "The provided code segment demonstrates the process of saving a trained neural network model in JSON format and its corresponding weights in HDF5 format. Initially, the model architecture is converted to JSON format and saved as \"model.json\". Then, the model's weights are saved as \"model.weights.h5\". Subsequently, the JSON model is loaded from the saved file, and the weights are loaded into the model. Finally, the loaded model is compiled and evaluated on the training data, yielding an accuracy of 83.60%. This process ensures that the trained model can be easily stored, retrieved, and utilized for inference tasks, offering flexibility and convenience in model deployment and usage."
      ],
      "metadata": {
        "id": "mZRDgT96AE85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save a model and load the model in a YAML format"
      ],
      "metadata": {
        "id": "mkSkA3E5s4Su"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import model_from_yaml\n",
        "model_yaml = model.to_json()\n",
        "with open(\"model.yaml\", \"w\") as yaml_file:\n",
        "    yaml_file.write(model_yaml)\n",
        "\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"/content/drive/MyDrive/Colab Notebooks/model_yaml.h5\")\n",
        "print(\"Saved model to disk as a YAML format\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR2zU49ds51p",
        "outputId": "fa8f879f-e38d-4fa7-f562-afcdcad12a07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk as a YAML format\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load YAML and create model\n",
        "yaml_file = open('model.yaml', 'r')\n",
        "loaded_model_yaml = yaml_file.read()\n",
        "yaml_file.close()\n",
        "loaded_model = model_from_json(loaded_model_yaml)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"/content/drive/MyDrive/Colab Notebooks/model_yaml.h5\")\n",
        "print(\"Loaded model from disk as a YAML format\")\n",
        "\n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
        "result = loaded_model.evaluate(X_train, encoded_y, verbose = 0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], result[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG6IdSBQs6W_",
        "outputId": "f4877834-d315-452b-c82a-c9316c2e2c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from disk as a YAML format\n",
            "accuracy: 83.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*ANALYSIS:*\n",
        "\n",
        "The provided code segment illustrates the process of saving a trained neural network model in YAML format along with its corresponding weights in HDF5 format. Initially, the model architecture is serialized to YAML and saved as \"model.yaml\". Subsequently, the model's weights are saved as \"model_yaml.h5\". Then, the YAML model is loaded from the saved file, and the weights are loaded into the model. Finally, the loaded model is compiled and evaluated on the training data, resulting in an accuracy of 83.60%. This method enables the convenient storage, retrieval, and utilization of the trained model, enhancing flexibility and ease of deployment for future inference tasks."
      ],
      "metadata": {
        "id": "vyezo0bOAcEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checkpoint Neural Network Model Improvements"
      ],
      "metadata": {
        "id": "2I5ZS4pUtPJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(6,)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
        "\n",
        "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "Checkpoint = ModelCheckpoint(filepath, monitor = 'val_accuracy', verbose = 1, save_best_only = True, mode = 'max')\n",
        "CallbackList = [Checkpoint]\n",
        "\n",
        "model.fit(X_train, encoded_y, validation_split = 0.2, epochs = 5000, batch_size = 100, callbacks = CallbackList, verbose = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H03FcoGVs6Oe",
        "outputId": "b7bc3f7a-e905-4824-b3f2-0b5466bd47d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "Epoch 2501: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2502: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2503: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2504: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2505: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2506: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2507: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2508: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2509: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2510: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2511: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2512: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2513: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2514: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2515: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2516: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2517: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2518: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2519: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2520: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2521: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2522: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2523: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2524: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2525: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2526: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2527: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2528: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2529: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2530: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2531: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2532: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2533: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2534: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2535: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2536: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2537: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2538: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2539: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2540: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2541: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2542: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2543: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2544: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2545: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2546: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2547: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2548: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2549: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2550: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2551: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2552: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2553: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2554: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2555: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2556: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2557: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2558: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2559: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2560: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2561: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2562: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2563: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2564: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2565: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2566: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2567: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2568: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2569: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2570: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2571: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2572: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2573: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2574: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2575: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2576: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2577: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2578: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2579: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2580: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2581: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2582: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2583: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2584: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2585: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2586: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2587: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2588: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2589: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2590: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2591: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2592: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2593: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2594: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2595: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2596: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2597: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2598: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2599: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2600: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2601: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2602: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2603: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2604: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2605: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2606: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2607: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2608: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2609: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2610: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2611: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2612: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2613: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2614: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2615: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2616: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2617: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2618: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2619: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2620: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2621: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2622: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2623: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2624: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2625: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2626: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2627: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2628: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2629: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2630: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2631: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2632: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2633: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2634: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2635: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2636: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2637: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2638: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2639: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2640: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2641: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2642: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2643: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2644: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2645: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2646: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2647: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2648: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2649: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2650: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2651: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2652: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2653: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2654: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2655: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2656: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2657: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2658: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2659: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2660: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2661: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2662: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2663: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2664: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2665: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2666: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2667: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2668: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2669: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2670: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2671: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2672: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2673: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2674: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2675: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2676: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2677: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2678: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2679: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2680: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2681: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2682: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2683: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2684: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2685: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2686: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2687: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2688: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2689: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2690: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2691: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2692: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2693: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2694: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2695: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2696: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2697: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2698: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2699: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2700: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2701: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2702: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2703: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2704: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2705: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2706: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2707: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2708: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2709: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2710: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2711: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2712: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2713: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2714: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2715: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2716: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2717: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2718: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2719: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2720: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2721: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2722: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2723: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2724: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2725: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2726: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2727: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2728: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2729: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2730: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2731: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2732: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2733: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2734: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2735: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2736: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2737: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2738: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2739: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2740: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2741: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2742: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2743: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2744: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2745: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2746: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2747: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2748: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2749: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2750: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2751: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2752: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2753: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2754: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2755: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2756: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2757: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2758: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2759: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2760: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2761: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2762: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2763: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2764: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2765: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2766: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2767: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2768: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2769: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2770: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2771: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2772: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2773: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2774: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2775: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2776: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2777: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2778: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2779: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2780: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2781: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2782: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2783: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2784: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2785: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2786: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2787: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2788: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2789: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2790: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2791: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2792: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2793: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2794: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2795: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2796: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2797: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2798: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2799: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2800: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2801: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2802: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2803: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2804: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2805: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2806: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2807: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2808: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2809: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2810: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2811: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2812: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2813: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2814: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2815: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2816: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2817: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2818: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2819: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2820: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2821: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2822: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2823: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2824: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2825: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2826: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2827: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2828: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2829: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2830: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2831: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2832: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2833: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2834: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2835: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2836: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2837: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2838: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2839: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2840: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2841: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2842: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2843: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2844: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2845: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2846: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2847: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2848: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2849: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2850: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2851: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2852: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2853: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2854: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2855: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2856: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2857: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2858: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2859: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2860: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2861: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2862: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2863: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2864: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2865: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2866: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2867: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2868: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2869: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2870: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2871: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2872: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2873: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2874: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2875: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2876: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2877: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2878: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2879: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2880: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2881: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2882: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2883: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2884: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2885: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2886: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2887: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2888: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2889: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2890: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2891: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2892: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2893: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2894: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2895: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2896: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2897: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2898: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2899: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2900: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2901: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2902: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2903: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2904: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2905: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2906: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2907: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2908: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2909: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2910: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2911: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2912: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2913: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2914: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2915: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2916: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2917: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2918: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2919: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2920: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2921: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2922: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2923: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2924: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2925: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2926: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2927: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2928: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2929: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2930: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2931: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2932: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2933: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2934: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2935: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2936: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2937: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2938: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2939: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2940: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2941: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2942: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2943: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2944: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2945: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2946: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2947: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2948: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2949: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2950: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2951: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2952: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2953: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2954: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2955: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2956: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2957: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2958: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2959: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2960: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2961: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2962: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2963: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2964: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2965: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2966: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2967: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2968: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2969: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2970: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2971: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2972: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2973: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2974: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2975: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2976: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2977: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2978: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2979: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2980: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2981: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2982: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2983: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2984: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2985: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2986: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2987: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2988: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2989: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2990: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2991: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2992: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2993: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2994: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2995: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2996: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2997: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2998: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 2999: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3000: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3001: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3002: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3003: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3004: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3005: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3006: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3007: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3008: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3009: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3010: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3011: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3012: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3013: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3014: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3015: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3016: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3017: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3018: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3019: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3020: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3021: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3022: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3023: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3024: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3025: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3026: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3027: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3028: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3029: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3030: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3031: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3032: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3033: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3034: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3035: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3036: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3037: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3038: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3039: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3040: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3041: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3042: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3043: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3044: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3045: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3046: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3047: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3048: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3049: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3050: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3051: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3052: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3053: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3054: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3055: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3056: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3057: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3058: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3059: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3060: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3061: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3062: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3063: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3064: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3065: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3066: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3067: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3068: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3069: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3070: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3071: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3072: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3073: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3074: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3075: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3076: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3077: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3078: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3079: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3080: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3081: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3082: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3083: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3084: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3085: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3086: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3087: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3088: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3089: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3090: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3091: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3092: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3093: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3094: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3095: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3096: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3097: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3098: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3099: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3100: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3101: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3102: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3103: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3104: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3105: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3106: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3107: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3108: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3109: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3110: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3111: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3112: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3113: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3114: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3115: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3116: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3117: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3118: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3119: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3120: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3121: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3122: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3123: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3124: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3125: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3126: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3127: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3128: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3129: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3130: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3131: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3132: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3133: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3134: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3135: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3136: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3137: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3138: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3139: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3140: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3141: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3142: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3143: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3144: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3145: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3146: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3147: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3148: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3149: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3150: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3151: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3152: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3153: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3154: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3155: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3156: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3157: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3158: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3159: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3160: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3161: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3162: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3163: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3164: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3165: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3166: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3167: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3168: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3169: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3170: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3171: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3172: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3173: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3174: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3175: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3176: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3177: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3178: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3179: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3180: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3181: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3182: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3183: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3184: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3185: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3186: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3187: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3188: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3189: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3190: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3191: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3192: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3193: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3194: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3195: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3196: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3197: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3198: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3199: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3200: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3201: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3202: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3203: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3204: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3205: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3206: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3207: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3208: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3209: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3210: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3211: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3212: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3213: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3214: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3215: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3216: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3217: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3218: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3219: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3220: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3221: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3222: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3223: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3224: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3225: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3226: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3227: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3228: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3229: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3230: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3231: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3232: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3233: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3234: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3235: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3236: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3237: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3238: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3239: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3240: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3241: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3242: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3243: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3244: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3245: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3246: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3247: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3248: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3249: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3250: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3251: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3252: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3253: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3254: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3255: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3256: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3257: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3258: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3259: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3260: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3261: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3262: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3263: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3264: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3265: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3266: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3267: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3268: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3269: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3270: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3271: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3272: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3273: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3274: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3275: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3276: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3277: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3278: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3279: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3280: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3281: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3282: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3283: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3284: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3285: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3286: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3287: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3288: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3289: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3290: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3291: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3292: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3293: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3294: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3295: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3296: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3297: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3298: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3299: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3300: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3301: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3302: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3303: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3304: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3305: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3306: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3307: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3308: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3309: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3310: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3311: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3312: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3313: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3314: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3315: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3316: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3317: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3318: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3319: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3320: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3321: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3322: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3323: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3324: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3325: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3326: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3327: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3328: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3329: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3330: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3331: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3332: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3333: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3334: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3335: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3336: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3337: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3338: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3339: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3340: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3341: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3342: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3343: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3344: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3345: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3346: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3347: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3348: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3349: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3350: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3351: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3352: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3353: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3354: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3355: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3356: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3357: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3358: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3359: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3360: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3361: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3362: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3363: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3364: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3365: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3366: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3367: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3368: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3369: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3370: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3371: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3372: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3373: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3374: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3375: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3376: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3377: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3378: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3379: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3380: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3381: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3382: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3383: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3384: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3385: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3386: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3387: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3388: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3389: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3390: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3391: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3392: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3393: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3394: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3395: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3396: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3397: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3398: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3399: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3400: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3401: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3402: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3403: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3404: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3405: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3406: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3407: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3408: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3409: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3410: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3411: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3412: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3413: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3414: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3415: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3416: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3417: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3418: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3419: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3420: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3421: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3422: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3423: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3424: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3425: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3426: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3427: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3428: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3429: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3430: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3431: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3432: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3433: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3434: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3435: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3436: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3437: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3438: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3439: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3440: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3441: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3442: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3443: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3444: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3445: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3446: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3447: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3448: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3449: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3450: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3451: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3452: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3453: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3454: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3455: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3456: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3457: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3458: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3459: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3460: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3461: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3462: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3463: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3464: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3465: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3466: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3467: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3468: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3469: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3470: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3471: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3472: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3473: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3474: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3475: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3476: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3477: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3478: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3479: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3480: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3481: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3482: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3483: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3484: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3485: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3486: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3487: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3488: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3489: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3490: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3491: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3492: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3493: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3494: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3495: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3496: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3497: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3498: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3499: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3500: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3501: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3502: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3503: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3504: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3505: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3506: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3507: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3508: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3509: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3510: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3511: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3512: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3513: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3514: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3515: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3516: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3517: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3518: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3519: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3520: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3521: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3522: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3523: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3524: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3525: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3526: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3527: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3528: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3529: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3530: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3531: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3532: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3533: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3534: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3535: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3536: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3537: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3538: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3539: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3540: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3541: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3542: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3543: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3544: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3545: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3546: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3547: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3548: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3549: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3550: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3551: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3552: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3553: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3554: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3555: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3556: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3557: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3558: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3559: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3560: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3561: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3562: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3563: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3564: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3565: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3566: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3567: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3568: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3569: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3570: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3571: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3572: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3573: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3574: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3575: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3576: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3577: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3578: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3579: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3580: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3581: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3582: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3583: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3584: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3585: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3586: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3587: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3588: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3589: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3590: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3591: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3592: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3593: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3594: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3595: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3596: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3597: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3598: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3599: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3600: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3601: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3602: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3603: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3604: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3605: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3606: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3607: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3608: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3609: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3610: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3611: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3612: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3613: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3614: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3615: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3616: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3617: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3618: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3619: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3620: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3621: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3622: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3623: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3624: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3625: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3626: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3627: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3628: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3629: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3630: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3631: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3632: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3633: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3634: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3635: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3636: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3637: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3638: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3639: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3640: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3641: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3642: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3643: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3644: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3645: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3646: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3647: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3648: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3649: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3650: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3651: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3652: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3653: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3654: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3655: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3656: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3657: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3658: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3659: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3660: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3661: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3662: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3663: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3664: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3665: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3666: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3667: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3668: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3669: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3670: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3671: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3672: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3673: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3674: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3675: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3676: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3677: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3678: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3679: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3680: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3681: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3682: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3683: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3684: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3685: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3686: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3687: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3688: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3689: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3690: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3691: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3692: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3693: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3694: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3695: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3696: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3697: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3698: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3699: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3700: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3701: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3702: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3703: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3704: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3705: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3706: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3707: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3708: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3709: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3710: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3711: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3712: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3713: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3714: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3715: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3716: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3717: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3718: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3719: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3720: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3721: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3722: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3723: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3724: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3725: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3726: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3727: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3728: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3729: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3730: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3731: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3732: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3733: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3734: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3735: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3736: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3737: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3738: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3739: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3740: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3741: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3742: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3743: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3744: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3745: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3746: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3747: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3748: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3749: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3750: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3751: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3752: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3753: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3754: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3755: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3756: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3757: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3758: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3759: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3760: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3761: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3762: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3763: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3764: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3765: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3766: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3767: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3768: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3769: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3770: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3771: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3772: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3773: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3774: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3775: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3776: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3777: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3778: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3779: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3780: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3781: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3782: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3783: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3784: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3785: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3786: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3787: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3788: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3789: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3790: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3791: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3792: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3793: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3794: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3795: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3796: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3797: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3798: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3799: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3800: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3801: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3802: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3803: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3804: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3805: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3806: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3807: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3808: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3809: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3810: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3811: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3812: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3813: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3814: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3815: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3816: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3817: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3818: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3819: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3820: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3821: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3822: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3823: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3824: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3825: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3826: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3827: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3828: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3829: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3830: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3831: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3832: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3833: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3834: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3835: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3836: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3837: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3838: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3839: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3840: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3841: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3842: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3843: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3844: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3845: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3846: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3847: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3848: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3849: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3850: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3851: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3852: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3853: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3854: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3855: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3856: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3857: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3858: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3859: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3860: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3861: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3862: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3863: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3864: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3865: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3866: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3867: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3868: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3869: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3870: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3871: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3872: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3873: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3874: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3875: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3876: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3877: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3878: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3879: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3880: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3881: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3882: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3883: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3884: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3885: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3886: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3887: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3888: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3889: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3890: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3891: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3892: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3893: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3894: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3895: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3896: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3897: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3898: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3899: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3900: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3901: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3902: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3903: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3904: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3905: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3906: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3907: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3908: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3909: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3910: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3911: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3912: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3913: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3914: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3915: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3916: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3917: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3918: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3919: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3920: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3921: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3922: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3923: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3924: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3925: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3926: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3927: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3928: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3929: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3930: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3931: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3932: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3933: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3934: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3935: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3936: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3937: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3938: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3939: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3940: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3941: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3942: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3943: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3944: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3945: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3946: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3947: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3948: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3949: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3950: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3951: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3952: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3953: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3954: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3955: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3956: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3957: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3958: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3959: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3960: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3961: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3962: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3963: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3964: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3965: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3966: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3967: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3968: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3969: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3970: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3971: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3972: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3973: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3974: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3975: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3976: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3977: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3978: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3979: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3980: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3981: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3982: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3983: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3984: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3985: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3986: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3987: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3988: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3989: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3990: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3991: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3992: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3993: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3994: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3995: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3996: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3997: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3998: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 3999: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4000: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4001: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4002: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4003: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4004: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4005: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4006: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4007: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4008: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4009: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4010: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4011: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4012: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4013: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4014: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4015: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4016: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4017: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4018: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4019: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4020: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4021: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4022: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4023: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4024: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4025: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4026: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4027: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4028: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4029: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4030: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4031: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4032: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4033: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4034: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4035: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4036: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4037: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4038: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4039: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4040: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4041: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4042: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4043: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4044: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4045: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4046: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4047: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4048: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4049: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4050: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4051: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4052: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4053: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4054: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4055: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4056: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4057: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4058: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4059: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4060: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4061: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4062: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4063: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4064: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4065: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4066: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4067: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4068: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4069: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4070: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4071: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4072: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4073: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4074: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4075: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4076: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4077: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4078: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4079: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4080: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4081: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4082: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4083: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4084: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4085: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4086: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4087: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4088: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4089: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4090: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4091: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4092: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4093: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4094: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4095: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4096: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4097: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4098: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4099: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4100: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4101: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4102: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4103: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4104: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4105: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4106: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4107: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4108: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4109: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4110: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4111: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4112: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4113: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4114: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4115: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4116: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4117: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4118: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4119: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4120: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4121: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4122: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4123: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4124: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4125: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4126: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4127: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4128: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4129: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4130: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4131: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4132: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4133: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4134: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4135: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4136: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4137: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4138: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4139: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4140: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4141: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4142: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4143: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4144: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4145: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4146: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4147: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4148: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4149: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4150: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4151: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4152: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4153: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4154: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4155: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4156: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4157: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4158: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4159: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4160: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4161: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4162: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4163: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4164: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4165: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4166: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4167: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4168: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4169: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4170: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4171: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4172: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4173: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4174: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4175: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4176: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4177: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4178: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4179: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4180: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4181: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4182: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4183: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4184: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4185: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4186: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4187: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4188: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4189: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4190: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4191: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4192: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4193: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4194: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4195: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4196: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4197: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4198: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4199: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4200: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4201: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4202: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4203: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4204: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4205: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4206: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4207: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4208: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4209: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4210: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4211: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4212: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4213: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4214: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4215: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4216: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4217: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4218: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4219: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4220: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4221: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4222: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4223: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4224: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4225: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4226: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4227: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4228: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4229: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4230: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4231: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4232: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4233: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4234: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4235: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4236: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4237: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4238: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4239: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4240: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4241: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4242: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4243: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4244: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4245: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4246: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4247: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4248: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4249: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4250: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4251: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4252: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4253: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4254: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4255: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4256: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4257: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4258: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4259: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4260: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4261: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4262: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4263: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4264: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4265: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4266: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4267: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4268: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4269: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4270: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4271: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4272: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4273: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4274: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4275: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4276: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4277: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4278: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4279: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4280: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4281: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4282: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4283: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4284: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4285: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4286: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4287: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4288: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4289: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4290: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4291: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4292: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4293: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4294: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4295: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4296: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4297: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4298: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4299: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4300: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4301: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4302: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4303: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4304: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4305: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4306: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4307: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4308: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4309: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4310: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4311: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4312: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4313: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4314: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4315: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4316: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4317: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4318: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4319: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4320: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4321: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4322: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4323: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4324: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4325: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4326: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4327: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4328: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4329: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4330: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4331: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4332: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4333: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4334: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4335: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4336: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4337: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4338: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4339: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4340: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4341: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4342: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4343: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4344: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4345: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4346: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4347: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4348: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4349: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4350: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4351: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4352: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4353: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4354: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4355: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4356: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4357: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4358: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4359: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4360: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4361: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4362: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4363: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4364: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4365: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4366: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4367: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4368: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4369: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4370: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4371: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4372: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4373: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4374: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4375: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4376: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4377: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4378: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4379: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4380: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4381: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4382: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4383: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4384: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4385: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4386: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4387: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4388: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4389: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4390: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4391: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4392: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4393: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4394: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4395: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4396: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4397: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4398: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4399: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4400: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4401: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4402: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4403: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4404: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4405: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4406: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4407: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4408: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4409: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4410: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4411: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4412: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4413: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4414: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4415: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4416: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4417: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4418: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4419: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4420: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4421: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4422: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4423: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4424: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4425: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4426: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4427: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4428: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4429: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4430: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4431: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4432: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4433: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4434: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4435: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4436: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4437: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4438: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4439: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4440: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4441: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4442: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4443: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4444: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4445: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4446: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4447: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4448: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4449: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4450: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4451: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4452: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4453: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4454: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4455: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4456: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4457: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4458: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4459: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4460: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4461: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4462: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4463: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4464: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4465: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4466: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4467: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4468: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4469: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4470: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4471: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4472: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4473: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4474: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4475: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4476: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4477: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4478: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4479: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4480: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4481: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4482: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4483: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4484: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4485: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4486: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4487: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4488: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4489: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4490: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4491: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4492: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4493: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4494: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4495: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4496: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4497: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4498: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4499: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4500: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4501: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4502: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4503: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4504: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4505: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4506: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4507: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4508: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4509: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4510: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4511: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4512: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4513: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4514: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4515: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4516: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4517: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4518: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4519: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4520: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4521: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4522: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4523: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4524: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4525: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4526: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4527: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4528: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4529: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4530: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4531: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4532: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4533: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4534: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4535: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4536: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4537: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4538: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4539: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4540: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4541: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4542: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4543: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4544: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4545: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4546: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4547: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4548: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4549: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4550: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4551: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4552: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4553: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4554: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4555: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4556: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4557: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4558: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4559: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4560: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4561: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4562: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4563: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4564: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4565: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4566: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4567: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4568: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4569: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4570: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4571: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4572: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4573: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4574: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4575: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4576: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4577: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4578: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4579: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4580: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4581: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4582: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4583: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4584: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4585: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4586: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4587: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4588: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4589: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4590: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4591: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4592: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4593: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4594: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4595: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4596: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4597: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4598: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4599: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4600: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4601: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4602: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4603: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4604: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4605: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4606: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4607: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4608: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4609: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4610: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4611: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4612: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4613: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4614: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4615: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4616: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4617: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4618: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4619: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4620: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4621: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4622: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4623: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4624: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4625: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4626: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4627: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4628: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4629: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4630: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4631: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4632: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4633: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4634: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4635: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4636: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4637: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4638: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4639: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4640: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4641: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4642: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4643: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4644: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4645: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4646: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4647: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4648: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4649: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4650: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4651: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4652: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4653: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4654: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4655: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4656: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4657: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4658: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4659: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4660: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4661: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4662: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4663: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4664: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4665: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4666: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4667: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4668: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4669: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4670: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4671: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4672: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4673: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4674: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4675: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4676: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4677: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4678: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4679: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4680: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4681: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4682: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4683: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4684: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4685: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4686: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4687: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4688: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4689: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4690: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4691: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4692: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4693: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4694: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4695: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4696: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4697: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4698: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4699: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4700: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4701: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4702: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4703: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4704: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4705: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4706: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4707: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4708: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4709: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4710: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4711: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4712: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4713: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4714: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4715: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4716: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4717: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4718: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4719: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4720: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4721: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4722: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4723: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4724: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4725: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4726: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4727: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4728: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4729: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4730: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4731: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4732: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4733: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4734: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4735: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4736: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4737: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4738: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4739: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4740: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4741: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4742: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4743: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4744: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4745: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4746: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4747: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4748: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4749: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4750: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4751: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4752: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4753: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4754: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4755: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4756: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4757: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4758: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4759: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4760: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4761: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4762: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4763: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4764: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4765: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4766: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4767: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4768: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4769: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4770: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4771: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4772: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4773: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4774: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4775: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4776: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4777: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4778: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4779: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4780: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4781: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4782: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4783: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4784: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4785: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4786: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4787: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4788: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4789: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4790: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4791: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4792: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4793: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4794: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4795: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4796: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4797: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4798: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4799: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4800: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4801: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4802: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4803: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4804: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4805: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4806: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4807: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4808: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4809: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4810: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4811: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4812: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4813: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4814: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4815: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4816: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4817: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4818: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4819: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4820: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4821: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4822: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4823: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4824: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4825: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4826: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4827: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4828: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4829: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4830: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4831: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4832: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4833: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4834: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4835: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4836: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4837: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4838: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4839: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4840: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4841: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4842: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4843: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4844: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4845: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4846: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4847: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4848: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4849: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4850: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4851: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4852: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4853: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4854: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4855: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4856: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4857: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4858: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4859: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4860: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4861: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4862: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4863: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4864: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4865: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4866: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4867: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4868: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4869: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4870: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4871: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4872: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4873: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4874: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4875: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4876: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4877: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4878: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4879: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4880: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4881: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4882: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4883: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4884: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4885: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4886: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4887: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4888: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4889: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4890: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4891: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4892: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4893: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4894: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4895: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4896: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4897: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4898: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4899: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4900: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4901: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4902: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4903: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4904: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4905: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4906: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4907: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4908: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4909: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4910: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4911: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4912: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4913: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4914: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4915: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4916: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4917: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4918: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4919: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4920: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4921: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4922: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4923: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4924: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4925: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4926: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4927: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4928: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4929: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4930: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4931: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4932: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4933: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4934: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4935: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4936: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4937: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4938: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4939: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4940: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4941: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4942: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4943: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4944: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4945: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4946: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4947: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4948: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4949: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4950: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4951: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4952: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4953: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4954: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4955: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4956: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4957: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4958: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4959: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4960: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4961: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4962: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4963: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4964: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4965: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4966: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4967: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4968: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4969: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4970: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4971: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4972: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4973: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4974: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4975: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4976: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4977: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4978: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4979: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4980: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4981: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4982: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4983: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4984: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4985: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4986: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4987: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4988: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4989: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4990: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4991: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4992: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4993: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4994: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4995: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4996: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4997: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4998: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 4999: val_accuracy did not improve from 0.73620\n",
            "\n",
            "Epoch 5000: val_accuracy did not improve from 0.73620\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7a3ffce61f00>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.evaluate(X_train, encoded_y, verbose = 0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], result[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46TVsk0XtqOL",
        "outputId": "d8cfea27-0cbd-49cc-d72e-4a27f173702f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 84.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checkpoint Best Neural Network Model only"
      ],
      "metadata": {
        "id": "wOB6SJWEvNxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(6,)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#Checkpoint for the best improvement\n",
        "filepath=\"weights.best.hdf5\"\n",
        "Checkpoint = ModelCheckpoint(filepath, monitor = 'val_accuracy', verbose = 1, save_best_only = True, mode = 'max')\n",
        "CallbackList = [Checkpoint]\n",
        "\n",
        "#Train the Model\n",
        "model.fit(X_train, encoded_y, validation_split = 0.1, epochs = 1000, batch_size = 30, callbacks = CallbackList, verbose = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBoSVvsDvPYu",
        "outputId": "1d8ee738-6cc2-45fd-ddac-45aa3aa0217c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.42683, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.42683 to 0.43902, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.43902 to 0.45122, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.45122 to 0.56098, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.56098\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.56098 to 0.58537, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.58537\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.58537\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.58537 to 0.59756, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.59756\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.59756\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.59756\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.59756\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.59756\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.59756\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.59756\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.59756\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.59756\n",
            "\n",
            "Epoch 19: val_accuracy improved from 0.59756 to 0.60976, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.60976\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.60976\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.60976\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.60976\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.60976\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.60976\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.60976\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.60976\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.60976\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.60976\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.60976\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.60976\n",
            "\n",
            "Epoch 32: val_accuracy improved from 0.60976 to 0.62195, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.62195\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.62195\n",
            "\n",
            "Epoch 35: val_accuracy improved from 0.62195 to 0.64634, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.64634\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.64634\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.64634\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.64634\n",
            "\n",
            "Epoch 40: val_accuracy improved from 0.64634 to 0.65854, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 51: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 52: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 58: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 60: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 61: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 62: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 63: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 65: val_accuracy did not improve from 0.65854\n",
            "\n",
            "Epoch 66: val_accuracy improved from 0.65854 to 0.68293, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 0.68293\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 0.68293\n",
            "\n",
            "Epoch 69: val_accuracy did not improve from 0.68293\n",
            "\n",
            "Epoch 70: val_accuracy improved from 0.68293 to 0.69512, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 0.69512\n",
            "\n",
            "Epoch 72: val_accuracy did not improve from 0.69512\n",
            "\n",
            "Epoch 73: val_accuracy did not improve from 0.69512\n",
            "\n",
            "Epoch 74: val_accuracy did not improve from 0.69512\n",
            "\n",
            "Epoch 75: val_accuracy did not improve from 0.69512\n",
            "\n",
            "Epoch 76: val_accuracy did not improve from 0.69512\n",
            "\n",
            "Epoch 77: val_accuracy did not improve from 0.69512\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 0.69512\n",
            "\n",
            "Epoch 79: val_accuracy did not improve from 0.69512\n",
            "\n",
            "Epoch 80: val_accuracy did not improve from 0.69512\n",
            "\n",
            "Epoch 81: val_accuracy did not improve from 0.69512\n",
            "\n",
            "Epoch 82: val_accuracy did not improve from 0.69512\n",
            "\n",
            "Epoch 83: val_accuracy did not improve from 0.69512\n",
            "\n",
            "Epoch 84: val_accuracy improved from 0.69512 to 0.71951, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 85: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 86: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 87: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 88: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 89: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 90: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 91: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 92: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 93: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 94: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 95: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 96: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 97: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 98: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 99: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 100: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 101: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 102: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 103: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 104: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 105: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 106: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 107: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 108: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 109: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 110: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 111: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 112: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 113: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 114: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 115: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 116: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 117: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 118: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 119: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 120: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 121: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 122: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 123: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 124: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 125: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 126: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 127: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 128: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 129: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 130: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 131: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 132: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 133: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 134: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 135: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 136: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 137: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 138: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 139: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 140: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 141: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 142: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 143: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 144: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 145: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 146: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 147: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 148: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 149: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 150: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 151: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 152: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 153: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 154: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 155: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 156: val_accuracy did not improve from 0.71951\n",
            "\n",
            "Epoch 157: val_accuracy improved from 0.71951 to 0.73171, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 158: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 159: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 160: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 161: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 162: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 163: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 164: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 165: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 166: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 167: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 168: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 169: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 170: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 171: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 172: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 173: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 174: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 175: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 176: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 177: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 178: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 179: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 180: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 181: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 182: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 183: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 184: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 185: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 186: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 187: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 188: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 189: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 190: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 191: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 192: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 193: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 194: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 195: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 196: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 197: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 198: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 199: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 200: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 201: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 202: val_accuracy did not improve from 0.73171\n",
            "\n",
            "Epoch 203: val_accuracy improved from 0.73171 to 0.74390, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 204: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 205: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 206: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 207: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 208: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 209: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 210: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 211: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 212: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 213: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 214: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 215: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 216: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 217: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 218: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 219: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 220: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 221: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 222: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 223: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 224: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 225: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 226: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 227: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 228: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 229: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 230: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 231: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 232: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 233: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 234: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 235: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 236: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 237: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 238: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 239: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 240: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 241: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 242: val_accuracy did not improve from 0.74390\n",
            "\n",
            "Epoch 243: val_accuracy improved from 0.74390 to 0.75610, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 244: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 245: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 246: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 247: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 248: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 249: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 250: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 251: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 252: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 253: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 254: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 255: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 256: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 257: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 258: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 259: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 260: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 261: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 262: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 263: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 264: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 265: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 266: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 267: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 268: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 269: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 270: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 271: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 272: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 273: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 274: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 275: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 276: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 277: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 278: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 279: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 280: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 281: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 282: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 283: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 284: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 285: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 286: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 287: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 288: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 289: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 290: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 291: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 292: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 293: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 294: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 295: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 296: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 297: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 298: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 299: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 300: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 301: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 302: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 303: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 304: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 305: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 306: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 307: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 308: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 309: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 310: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 311: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 312: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 313: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 314: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 315: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 316: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 317: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 318: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 319: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 320: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 321: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 322: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 323: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 324: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 325: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 326: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 327: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 328: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 329: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 330: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 331: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 332: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 333: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 334: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 335: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 336: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 337: val_accuracy did not improve from 0.75610\n",
            "\n",
            "Epoch 338: val_accuracy improved from 0.75610 to 0.76829, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 339: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 340: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 341: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 342: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 343: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 344: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 345: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 346: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 347: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 348: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 349: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 350: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 351: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 352: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 353: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 354: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 355: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 356: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 357: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 358: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 359: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 360: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 361: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 362: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 363: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 364: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 365: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 366: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 367: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 368: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 369: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 370: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 371: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 372: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 373: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 374: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 375: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 376: val_accuracy did not improve from 0.76829\n",
            "\n",
            "Epoch 377: val_accuracy improved from 0.76829 to 0.78049, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 378: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 379: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 380: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 381: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 382: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 383: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 384: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 385: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 386: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 387: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 388: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 389: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 390: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 391: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 392: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 393: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 394: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 395: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 396: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 397: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 398: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 399: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 400: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 401: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 402: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 403: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 404: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 405: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 406: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 407: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 408: val_accuracy did not improve from 0.78049\n",
            "\n",
            "Epoch 409: val_accuracy improved from 0.78049 to 0.79268, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 410: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 411: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 412: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 413: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 414: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 415: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 416: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 417: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 418: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 419: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 420: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 421: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 422: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 423: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 424: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 425: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 426: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 427: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 428: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 429: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 430: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 431: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 432: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 433: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 434: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 435: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 436: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 437: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 438: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 439: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 440: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 441: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 442: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 443: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 444: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 445: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 446: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 447: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 448: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 449: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 450: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 451: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 452: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 453: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 454: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 455: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 456: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 457: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 458: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 459: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 460: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 461: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 462: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 463: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 464: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 465: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 466: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 467: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 468: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 469: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 470: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 471: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 472: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 473: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 474: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 475: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 476: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 477: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 478: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 479: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 480: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 481: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 482: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 483: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 484: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 485: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 486: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 487: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 488: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 489: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 490: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 491: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 492: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 493: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 494: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 495: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 496: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 497: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 498: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 499: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 500: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 501: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 502: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 503: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 504: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 505: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 506: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 507: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 508: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 509: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 510: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 511: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 512: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 513: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 514: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 515: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 516: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 517: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 518: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 519: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 520: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 521: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 522: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 523: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 524: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 525: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 526: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 527: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 528: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 529: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 530: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 531: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 532: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 533: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 534: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 535: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 536: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 537: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 538: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 539: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 540: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 541: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 542: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 543: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 544: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 545: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 546: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 547: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 548: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 549: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 550: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 551: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 552: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 553: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 554: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 555: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 556: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 557: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 558: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 559: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 560: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 561: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 562: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 563: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 564: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 565: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 566: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 567: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 568: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 569: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 570: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 571: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 572: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 573: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 574: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 575: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 576: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 577: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 578: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 579: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 580: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 581: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 582: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 583: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 584: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 585: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 586: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 587: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 588: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 589: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 590: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 591: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 592: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 593: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 594: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 595: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 596: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 597: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 598: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 599: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 600: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 601: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 602: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 603: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 604: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 605: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 606: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 607: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 608: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 609: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 610: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 611: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 612: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 613: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 614: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 615: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 616: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 617: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 618: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 619: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 620: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 621: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 622: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 623: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 624: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 625: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 626: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 627: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 628: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 629: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 630: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 631: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 632: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 633: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 634: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 635: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 636: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 637: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 638: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 639: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 640: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 641: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 642: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 643: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 644: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 645: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 646: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 647: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 648: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 649: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 650: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 651: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 652: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 653: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 654: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 655: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 656: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 657: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 658: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 659: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 660: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 661: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 662: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 663: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 664: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 665: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 666: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 667: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 668: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 669: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 670: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 671: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 672: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 673: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 674: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 675: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 676: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 677: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 678: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 679: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 680: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 681: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 682: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 683: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 684: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 685: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 686: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 687: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 688: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 689: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 690: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 691: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 692: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 693: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 694: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 695: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 696: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 697: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 698: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 699: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 700: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 701: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 702: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 703: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 704: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 705: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 706: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 707: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 708: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 709: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 710: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 711: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 712: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 713: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 714: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 715: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 716: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 717: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 718: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 719: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 720: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 721: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 722: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 723: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 724: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 725: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 726: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 727: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 728: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 729: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 730: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 731: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 732: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 733: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 734: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 735: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 736: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 737: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 738: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 739: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 740: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 741: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 742: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 743: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 744: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 745: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 746: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 747: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 748: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 749: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 750: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 751: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 752: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 753: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 754: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 755: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 756: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 757: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 758: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 759: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 760: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 761: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 762: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 763: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 764: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 765: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 766: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 767: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 768: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 769: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 770: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 771: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 772: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 773: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 774: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 775: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 776: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 777: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 778: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 779: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 780: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 781: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 782: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 783: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 784: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 785: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 786: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 787: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 788: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 789: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 790: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 791: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 792: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 793: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 794: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 795: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 796: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 797: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 798: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 799: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 800: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 801: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 802: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 803: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 804: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 805: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 806: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 807: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 808: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 809: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 810: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 811: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 812: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 813: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 814: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 815: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 816: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 817: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 818: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 819: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 820: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 821: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 822: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 823: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 824: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 825: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 826: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 827: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 828: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 829: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 830: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 831: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 832: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 833: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 834: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 835: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 836: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 837: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 838: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 839: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 840: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 841: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 842: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 843: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 844: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 845: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 846: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 847: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 848: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 849: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 850: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 851: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 852: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 853: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 854: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 855: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 856: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 857: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 858: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 859: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 860: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 861: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 862: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 863: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 864: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 865: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 866: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 867: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 868: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 869: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 870: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 871: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 872: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 873: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 874: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 875: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 876: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 877: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 878: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 879: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 880: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 881: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 882: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 883: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 884: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 885: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 886: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 887: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 888: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 889: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 890: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 891: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 892: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 893: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 894: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 895: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 896: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 897: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 898: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 899: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 900: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 901: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 902: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 903: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 904: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 905: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 906: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 907: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 908: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 909: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 910: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 911: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 912: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 913: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 914: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 915: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 916: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 917: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 918: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 919: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 920: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 921: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 922: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 923: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 924: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 925: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 926: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 927: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 928: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 929: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 930: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 931: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 932: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 933: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 934: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 935: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 936: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 937: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 938: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 939: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 940: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 941: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 942: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 943: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 944: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 945: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 946: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 947: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 948: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 949: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 950: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 951: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 952: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 953: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 954: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 955: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 956: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 957: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 958: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 959: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 960: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 961: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 962: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 963: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 964: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 965: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 966: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 967: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 968: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 969: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 970: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 971: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 972: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 973: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 974: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 975: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 976: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 977: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 978: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 979: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 980: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 981: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 982: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 983: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 984: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 985: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 986: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 987: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 988: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 989: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 990: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 991: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 992: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 993: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 994: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 995: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 996: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 997: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 998: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 999: val_accuracy did not improve from 0.79268\n",
            "\n",
            "Epoch 1000: val_accuracy did not improve from 0.79268\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7a40059c3490>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model.evaluate(X_train, encoded_y, verbose = 0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], output[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxvLJpflvP4i",
        "outputId": "e3a6f8de-790c-4d08-dd77-2535a66a2995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 87.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load a saved Neural Network model"
      ],
      "metadata": {
        "id": "dw8qwjxZxNbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(6,)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.load_weights('weights.best.hdf5')\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "print(\"Created model and loaded weights from file\")\n",
        "\n",
        "Load_result = model.evaluate(X_train, encoded_y, verbose = 0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], Load_result[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXsBTNWfxPD9",
        "outputId": "802f4d53-1762-4908-eb20-a0bf1d353dec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created model and loaded weights from file\n",
            "accuracy: 86.44%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize Model Training History in Keras"
      ],
      "metadata": {
        "id": "vf3zhq2ox33H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(6,)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'SGD', metrics = ['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, encoded_y, validation_split=0.2, epochs=500, batch_size=20, verbose=0)\n",
        "\n",
        "\n",
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "id": "PqdjW1OCx6DZ",
        "outputId": "24ae4c1c-8f27-4ecc-a7b9-0b5f9c46b2fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***ANALYSIS:***\n",
        "\n",
        "The provided code segment defines a neural network model using the Sequential API with various dense layers and softmax activation for multiclass classification. The model is compiled with categorical cross-entropy as the loss function, stochastic gradient descent (SGD) optimizer, and accuracy as the evaluation metric. Subsequently, the model is trained on the training data 'X_train' and the encoded target variable 'encoded_y' for 500 epochs with a batch size of 20 and a validation split of 20%. The training history is then visualized, showing the model's accuracy and loss on both the training and validation sets across epochs."
      ],
      "metadata": {
        "id": "Dmas-fQsDnf5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show the application of Dropout Regularization"
      ],
      "metadata": {
        "id": "y7u_cP3Oyk2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "metadata": {
        "id": "SH1GlizC9i45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "MHealthRisk_df = pd.read_csv(\"/content/Maternal Health Risk Data Set.csv\")\n",
        "\n",
        "dataset = MHealthRisk_df"
      ],
      "metadata": {
        "id": "ASLTxSKM9i1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scale_LE = LabelEncoder()\n",
        "for i in MHealthRisk_df:\n",
        "  if MHealthRisk_df[i].dtypes == 'object':\n",
        "    MHealthRisk_df[i] = scale_LE.fit_transform(MHealthRisk_df[i])\n",
        "  else:\n",
        "    pass\n",
        "MHealthRisk_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUEXyZk_9ixH",
        "outputId": "54c5397e-cd38-4a46-a1e1-027872aec0b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1014 entries, 0 to 1013\n",
            "Data columns (total 7 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   Age          1014 non-null   int64  \n",
            " 1   SystolicBP   1014 non-null   int64  \n",
            " 2   DiastolicBP  1014 non-null   int64  \n",
            " 3   BS           1014 non-null   float64\n",
            " 4   BodyTemp     1014 non-null   float64\n",
            " 5   HeartRate    1014 non-null   int64  \n",
            " 6   RiskLevel    1014 non-null   int64  \n",
            "dtypes: float64(2), int64(5)\n",
            "memory usage: 55.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MHealthRisk_df.corr()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "WXzQ6KgL9iq2",
        "outputId": "01924846-9a5c-43fb-f1aa-ca9de14c8494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Age  SystolicBP  DiastolicBP        BS  BodyTemp  HeartRate  \\\n",
              "Age          1.000000    0.416045     0.398026  0.473284 -0.255323   0.079798   \n",
              "SystolicBP   0.416045    1.000000     0.787006  0.425172 -0.286616  -0.023108   \n",
              "DiastolicBP  0.398026    0.787006     1.000000  0.423824 -0.257538  -0.046151   \n",
              "BS           0.473284    0.425172     0.423824  1.000000 -0.103493   0.142867   \n",
              "BodyTemp    -0.255323   -0.286616    -0.257538 -0.103493  1.000000   0.098771   \n",
              "HeartRate    0.079798   -0.023108    -0.046151  0.142867  0.098771   1.000000   \n",
              "RiskLevel   -0.211851   -0.208797    -0.284633 -0.479958 -0.006680  -0.111637   \n",
              "\n",
              "             RiskLevel  \n",
              "Age          -0.211851  \n",
              "SystolicBP   -0.208797  \n",
              "DiastolicBP  -0.284633  \n",
              "BS           -0.479958  \n",
              "BodyTemp     -0.006680  \n",
              "HeartRate    -0.111637  \n",
              "RiskLevel     1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a598c53e-945a-42c6-bed3-60b610ad071f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>SystolicBP</th>\n",
              "      <th>DiastolicBP</th>\n",
              "      <th>BS</th>\n",
              "      <th>BodyTemp</th>\n",
              "      <th>HeartRate</th>\n",
              "      <th>RiskLevel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.416045</td>\n",
              "      <td>0.398026</td>\n",
              "      <td>0.473284</td>\n",
              "      <td>-0.255323</td>\n",
              "      <td>0.079798</td>\n",
              "      <td>-0.211851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SystolicBP</th>\n",
              "      <td>0.416045</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.787006</td>\n",
              "      <td>0.425172</td>\n",
              "      <td>-0.286616</td>\n",
              "      <td>-0.023108</td>\n",
              "      <td>-0.208797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DiastolicBP</th>\n",
              "      <td>0.398026</td>\n",
              "      <td>0.787006</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.423824</td>\n",
              "      <td>-0.257538</td>\n",
              "      <td>-0.046151</td>\n",
              "      <td>-0.284633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BS</th>\n",
              "      <td>0.473284</td>\n",
              "      <td>0.425172</td>\n",
              "      <td>0.423824</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.103493</td>\n",
              "      <td>0.142867</td>\n",
              "      <td>-0.479958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BodyTemp</th>\n",
              "      <td>-0.255323</td>\n",
              "      <td>-0.286616</td>\n",
              "      <td>-0.257538</td>\n",
              "      <td>-0.103493</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.098771</td>\n",
              "      <td>-0.006680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HeartRate</th>\n",
              "      <td>0.079798</td>\n",
              "      <td>-0.023108</td>\n",
              "      <td>-0.046151</td>\n",
              "      <td>0.142867</td>\n",
              "      <td>0.098771</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.111637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RiskLevel</th>\n",
              "      <td>-0.211851</td>\n",
              "      <td>-0.208797</td>\n",
              "      <td>-0.284633</td>\n",
              "      <td>-0.479958</td>\n",
              "      <td>-0.006680</td>\n",
              "      <td>-0.111637</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a598c53e-945a-42c6-bed3-60b610ad071f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a598c53e-945a-42c6-bed3-60b610ad071f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a598c53e-945a-42c6-bed3-60b610ad071f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-537bef12-721e-4c85-8599-3f0ad65da186\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-537bef12-721e-4c85-8599-3f0ad65da186')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-537bef12-721e-4c85-8599-3f0ad65da186 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"MHealthRisk_df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4389859865570124,\n        \"min\": -0.25532313920501565,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1.0,\n          0.4160454479747322,\n          0.0797976348285774\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SystolicBP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4939108178226137,\n        \"min\": -0.2866155235428736,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.4160454479747322,\n          1.0,\n          -0.023107956988353304\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DiastolicBP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.50393125749222,\n        \"min\": -0.2846334952168584,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.3980262867031837,\n          0.78700647697753,\n          -0.04615057091697736\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4725907093021242,\n        \"min\": -0.4799580508546492,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.4732843359291685,\n          0.4251716592710181,\n          0.14286722659941492\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BodyTemp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4525973307113755,\n        \"min\": -0.2866155235428736,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          -0.25532313920501565,\n          -0.2866155235428736,\n          0.09877104396427468\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HeartRate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.37987456818871423,\n        \"min\": -0.11163740035420522,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.0797976348285774,\n          -0.023107956988353304,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RiskLevel\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4829073009411157,\n        \"min\": -0.4799580508546492,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          -0.21185116042052668,\n          -0.2087971130640691,\n          -0.11163740035420522\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK OUTLIERS\n",
        "corr_var = MHealthRisk_df.corr()\n",
        "corr_targ = corr_var['Age']\n",
        "corr_abs = corr_targ.abs()\n",
        "low_corr = corr_abs[corr_abs <= 0.1].index.tolist()\n",
        "print(low_corr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Osq3RryQ9v7z",
        "outputId": "3d9f956e-b03c-4908-a95d-c35a5e4615c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['HeartRate']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# split the data to separate features (X) and target labels (Y)\n",
        "x = MHealthRisk_df.drop(columns = 'RiskLevel')\n",
        "y = MHealthRisk_df['RiskLevel']\n",
        "\n",
        "# split the dataset into training and testing sets (70% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_norm, y, test_size = 0.2, random_state = 1111)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r3GTK0n9zDv",
        "outputId": "a389b73e-cdfa-4ae3-ba46-2ec6903501f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((811, 6), (203, 6), (811,), (203,))"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# REMOVE OUTLIER\n",
        "\n",
        "rem_out = MHealthRisk_df.drop(columns = low_corr)\n",
        "MHealthRisk_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DveY1hk_9xcW",
        "outputId": "81b5eb34-dabc-4e37-96aa-aa8b95be6e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1014 entries, 0 to 1013\n",
            "Data columns (total 7 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   Age          1014 non-null   int64  \n",
            " 1   SystolicBP   1014 non-null   int64  \n",
            " 2   DiastolicBP  1014 non-null   int64  \n",
            " 3   BS           1014 non-null   float64\n",
            " 4   BodyTemp     1014 non-null   float64\n",
            " 5   HeartRate    1014 non-null   int64  \n",
            " 6   RiskLevel    1014 non-null   int64  \n",
            "dtypes: float64(2), int64(5)\n",
            "memory usage: 55.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "utils_le = LabelEncoder()\n",
        "utils_le.fit(y_train)\n",
        "y_utils_le = utils_le.transform(y_train)\n",
        "encoded_y = to_categorical(y_utils_le)"
      ],
      "metadata": {
        "id": "h39lD_JC94D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def create_baseline():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(6,)))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(8, activation='relu'))\n",
        "    model.add(Dense(12, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # Compile model\n",
        "    sgd = SGD(learning_rate=0.01, momentum=0.8)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=300, batch_size=16, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "results = cross_val_score(pipeline, X_train, encoded_y[:, 0], cv=kfold)\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J45Wfp7s_GNz",
        "outputId": "65dbaa22-cb3a-4109-e0a8-a5770ec1e573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-124-2d5d4796aefe>:27: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=300, batch_size=16, verbose=0)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline: 91.61% (3.66%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show the application of Dropout on the visible layer"
      ],
      "metadata": {
        "id": "U17AiGXU_eIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def create_baseline():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dropout(0.2, Input(shape=(6,)))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(8, activation='relu'))\n",
        "    model.add(Dense(12, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # Compile model\n",
        "    sgd = SGD(learning_rate=0.01, momentum=0.8)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=10, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "results = cross_val_score(pipeline, X_train, encoded_y[:, 0], cv=kfold)\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1akFaz0kAk9W",
        "outputId": "4d1339c9-2a93-417b-ecca-ea4a0514998a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-135-a6afda1e2f5b>:26: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=10, verbose=0)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline: 91.24% (2.57%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show the application of Dropout on the hidden layer"
      ],
      "metadata": {
        "id": "gYye8Gcd_m_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def create_baseline():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(6,)))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(8, activation='relu'))\n",
        "    model.add(Dense(12, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # Compile model\n",
        "    sgd = SGD(learning_rate=0.01, momentum=0.8)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=50, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "results = cross_val_score(pipeline, X_train, encoded_y[:, 0], cv=kfold)\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQHdyyNREqaE",
        "outputId": "17456943-8e40-4308-b18f-78ffe5234e28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-136-ff97cbc05e82>:26: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=50, batch_size=5, verbose=0)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline: 91.37% (2.58%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show the application of a time-based learning rate schedule\n"
      ],
      "metadata": {
        "id": "3u7HDNQO_qdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def create_baseline():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(6,)))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(8, activation='relu'))\n",
        "    model.add(Dense(12, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # Compile model\n",
        "    sgd = SGD(learning_rate=0.01, momentum=0.8)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "results = cross_val_score(pipeline, X_train, encoded_y[:, 0], cv=kfold)\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGLqvmsVCzoh",
        "outputId": "d3a6e0ed-c634-416b-f958-683c0353dc2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-137-73b2ab792a6e>:26: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline: 91.37% (2.13%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show the application of a drop-based learning rate schedule\n",
        "\n"
      ],
      "metadata": {
        "id": "8dVr1kTQ_sKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def create_baseline():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(6,)))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(8, activation='relu'))\n",
        "    model.add(Dense(12, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # Compile model\n",
        "    sgd = SGD(learning_rate=0.01, momentum=0.8)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "results = cross_val_score(pipeline, X_train, encoded_y[:, 0], cv=kfold)\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "metadata": {
        "id": "mVxOEsuWE8ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c3335b-5d43-4e49-f3b7-5f71256b79e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-138-73b2ab792a6e>:26: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONCLUSION / LEARNING\n",
        "\n",
        "From this hands-on activity, I've learned the importance of saving neural network models for future use. By serializing the model architecture into formats like JSON or YAML and saving the weights separately in HDF5 format, we can preserve the trained model's structure and parameters. This allows us to easily reload the model for inference without needing to retrain it, saving time and computational resources. Additionally, storing the model and weights in cloud storage platforms like Google Drive enables accessibility from different environments. Through this process, I've gained insight into the practical aspects of model serialization and weight saving, enhancing my understanding of model deployment and facilitating future projects by streamlining the model reuse process."
      ],
      "metadata": {
        "id": "peRYqqZ8_umE"
      }
    }
  ]
}